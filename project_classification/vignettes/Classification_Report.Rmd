---
title: "Classification Report"
author: "Tay Jing Rui"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(targets)
library(ggplot2)
library(dplyr)
library(caret)
library(corrplot)
library(gridExtra)
raw_data <- tar_read(raw_data)
cleaned_data <- tar_read(cleaned_data)
eda_results <- tar_read(eda_results)
evaluation <- tar_read(evaluation)
```
# Introduction
Pedestrian safety is always a concern in our modern transportation systems as the amount of vehicles are increasing on the streets. The ability to predict the severity of these casualties is crucial for implementing prevention strategies. This project aims to develop and evaluate machine learning models that can accurately classify the severity of pedestrian casualties (“Fatal,” “Serious,” or “Slight”) based on detailed accident data. The primary objectives are to understand the main factors causing increase of casualties across the severity rate and interpret our analysis for road safety improvements. We will be focusing slightly more on Fatal cases predictions as those are the incidents which are more concerning.  

his project aims to develop and evaluate machine learning models that can accurately classify the severity of pedestrian casualties (“Fatal,” “Serious,” or “Slight”) based on detailed accident data. The primary objectives is to understand the main factors causing increase of casualties across the severity rate and interpret our analysis for road safety improvements. We will be focusing slightly more on Fatal cases predcitions as those are the incidents which are more concerning. 

# Data Preparation
After loading our pedestrian data into a dataframe by pulling from databse using DBI and PostGRES , we observe that summary of it to understand its basic structure. We have a 1420x83 dataset. We then checked for NA values, finding numerous missing data from this dataset.  

# EDA before handling and FE

Our summary data also shows quite large range which indicates that many variables has outliers like engine capacity, age features and spatial outliers for grids features. We also observed some negative numbers in road number and vehicle type which suggests errorneous input. 

To evaluate the predictive value of each feature in the raw dataset, I trained a random forest classifier and examined the resulting variable importance table. The MeanDecreaseGini metric was used to rank features by their contribution to classification accuracy. The analysis showed that variables such as age_of_casualty, engine_capacity_cc, geographic coordinates (longitude, latitude, grid_x), age_of_driver, obs_hour, and speed_limit_mph had the highest importance scores. Features with low or near-zero importance, such as obs_year, were considered less relevant for predicting casualty severity and could be excluded from further modeling or feature engineering.

```{r}
# Distribution of Casualty Severity
eda_results$severity_dist
```
We showed the balanced of classes for our target variable, casualty_severity, which shows not much imbalance in class as shown above. 
```{r}
# Correlation Plot
eda_results$corr_matrix
```
Next, we examined the correlations among the numeric variables to determine which features are high correlated and have to potentially handle them to mitigate multicollinearity issues. We that the geographical features like grid_x and grid_y are highly correlated to longitude and latitude. Indicating we only have to keep a pair of them in our features. Certain reference variables are also showing high correlations which we have to drop.

# Data Handling and Feature Engineering
We first removed columns that contains all NA values as they do not provide any value to our analysis and for the other missing values, we employed imputation based on variable types. We imputed median for numeric columns which is more robust for outliers while imputing most common value for character and factor data type.
We then exclude identification columns and features which can potentially cause data leakages like accident_index, vehicle_reference and enhanced_casualty_severity. We fitted random forest to our data with its importance metrics to identify which features contributed the most in predicting our casualty_severity target variable and exclude those with low importance score.
For feature engineering, original obs_date was split into obs_weekday, obs_hour, obs_month, obs_year for date time features. We then bin the continuous variables like casualty_age_group into (Child, Youth, Adult, Elderly), driver_age_group into (Young, Adult, Middle, Senior), speed_zone into (Low, Medium, High), engine_size_group into (Small, Medium, Large). We followed by featuring indicator variables; is_night (1=dark, 0=daylight), is_urban (1=urban, 0=rural), vulnerable_pedestrian (1=Child, 0=Elderly), on_crossing (1=yes, 0=no). 

We further computed high cardinality columns after factorizing character data and drop those with more than 30 unique levels and variables like identifiers, references and features like accident_severity.
We finally used all the featured variables and the remaining relevant variables after we have decided on the feature importance and cleaning for our model. 

# EDA Visualisation after FE
```{r}
# Feature engineered variable bar plots
gridExtra::grid.arrange(
  eda_results$speed_vs_severity,
  eda_results$night_vs_severity,
  eda_results$engine_vs_severity,
  eda_results$age_vs_severity,
  ncol=2
)
```
The above bar plots shows the distribution of the feature engineered variables with respect to casualty_severity. Speed zone showing high casualty across all severity in medium speed zone, this could be areas where many people are around like city areas whereas high speed places like express ways could have lesser chances of pedestrians. We see that Fatal cases happen more often at night which is not surprising but not by much as compared to day. Overall, more accidents occur in the day as more pedestrians are outside. Engine size of medium caused significant more casualties may be due to the population of certain cars on the road. Interestingly, adults age group has the highest count for casualties across all severity due probably due to the highest age range categorised. But Seniors accidents prove to have a lot of fatal cases than serious and slight within Senior group itself.

# Model Train
Data is split into training and testing sets using stratified sampling to maintain class distribution. Cross validation of 5 folds with SMOTE is also used to address class imbalance and ensuring that our model is robust enough for evaluation. Three models are being trained; Multinomial Classification, Random Forest and XGBoost.

Models are then evaluated using confusion matrix and ROC/AUC on the test set, each comparing their predictive capability with our chosen features. 

# Results
```{r}
evaluation$cm_multinom
evaluation$cm_rf
evaluation$cm_xgb

cat("Multinomial AUC:", evaluation$auc_multinom, "\n")
cat("Random Forest AUC:", evaluation$auc_rf, "\n")
cat("XGBoost AUC:", evaluation$auc_xgb, "\n")
```

Confusion Matrix shows that our Random Forest yielded the best accuracy of 57.6%, outperforming XGBoost of 55.5% and Multinomial of 56.5% but not by much. XGBoost consistently performing slightly lower for all macro metrics. Kappa value shows RF having the highest of 0.360 as compared to Multinomial and XGBoost of 0.348 and 0.331 respectively. Kappa reflects a "fair-to-moderate" agreement, suggesting moderately better than random guessing but its value is not considered good.  All models have performed better than the baseline No Information Rate of 36% indicating that Multinomial is not just guessing for the majority of the class but learning patterns and making good predictions. Our macro metrics tells us that all models perform very similarly with RF taking a slight lead in all evaluations metrices. 

Per class metrics shows that Multinomial consistently achieving the highest in precision, recall and balanced accuracy across all classes. This suggests that evaluating within each class, multinomial is the most reliable and accurate in its predictions. RF may be better in macro accuracy due to it being more balanced, but it falls behind quite a bit in single class. XGBoost performed better than RF in per class metrics but does not really stand out in any way as compared to Multinomial. 

From our ROC-AUC, all 3 models achieved around 75% suggests good overall class discrimination in their prediction, with Multinomial at 0.755, RF at 0.742 and XGBoost at 0.75. Multinomial achieving the highest AUC has just a slight edge over the other 2 models. 

# Conclusion

All models performed better than random guessing and are best at predicting Fatal cases. Performance for the Fatal class is highest in terms of recall for the Multinomial Logistic Regression, indicating it is best at detecting Fatal cases. RF may have the highest macro accuracy but Multinomial is only 1% lower and that it outperformed in per class metrics and AUC/ROC metric. Based on our goal in identifying per crisis, especially Fatal incidents analysis. Multinomial Logistic Regression is preferred and is appropriate to be the final model. 
